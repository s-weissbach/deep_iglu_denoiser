{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils.trainfiles import TrainFiles\n",
    "from utils.dataloader import DataLoader\n",
    "from model.unet import UNet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU ready')\n",
    "else:\n",
    "    print('Warning: only CPU found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate trainfiles.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfiles = TrainFiles('trainfiles.yaml',True)\n",
    "trainfiles.find_files('/home/stephan/Desktop/',['.stk'], 4, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfiles = TrainFiles('trainfiles.json',False)\n",
    "dataloader = DataLoader(trainfiles,batch_size=6,n_pre=2,n_post=2,train_height=400,train_width=400,load_multiple_targets_per_file=True,n_multiple_targets=1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = UNet(dataloader.n_pre + dataloader.n_post).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 (samples 6), Loss: 0.6909609436988831\n",
      "Batch 11 (samples 66), Loss: 0.27553391456604004\n",
      "Batch 21 (samples 126), Loss: 0.2531118392944336\n",
      "Batch 31 (samples 186), Loss: 0.26683464646339417\n",
      "Batch 41 (samples 246), Loss: 0.31963130831718445\n",
      "Batch 51 (samples 306), Loss: 0.24245847761631012\n",
      "Batch 61 (samples 366), Loss: 0.22504113614559174\n",
      "Batch 71 (samples 426), Loss: 0.20224836468696594\n",
      "Batch 81 (samples 486), Loss: 0.23596012592315674\n",
      "Batch 91 (samples 546), Loss: 0.25659382343292236\n",
      "Batch 101 (samples 606), Loss: 0.2831600308418274\n",
      "Batch 111 (samples 666), Loss: 0.28144851326942444\n",
      "Batch 121 (samples 726), Loss: 0.1920897662639618\n",
      "Batch 131 (samples 786), Loss: 0.20388203859329224\n",
      "Batch 141 (samples 846), Loss: 0.30912312865257263\n",
      "Batch 151 (samples 906), Loss: 0.2366148829460144\n",
      "Batch 161 (samples 966), Loss: 0.26700469851493835\n",
      "Batch 171 (samples 1026), Loss: 0.3314131498336792\n",
      "Batch 181 (samples 1086), Loss: 0.23139716684818268\n",
      "Batch 191 (samples 1146), Loss: 0.2491946518421173\n",
      "Batch 201 (samples 1206), Loss: 0.2898825407028198\n",
      "Batch 211 (samples 1266), Loss: 0.29046592116355896\n",
      "Batch 221 (samples 1326), Loss: 0.2151777744293213\n",
      "Batch 231 (samples 1386), Loss: 0.23722559213638306\n",
      "Batch 241 (samples 1446), Loss: 0.26552116870880127\n",
      "Batch 251 (samples 1506), Loss: 0.23265202343463898\n",
      "Batch 261 (samples 1566), Loss: 0.3023649752140045\n",
      "Batch 271 (samples 1626), Loss: 0.23093649744987488\n",
      "Batch 281 (samples 1686), Loss: 0.25482168793678284\n",
      "Batch 291 (samples 1746), Loss: 0.27463629841804504\n",
      "Batch 301 (samples 1806), Loss: 0.34344372153282166\n",
      "Batch 311 (samples 1866), Loss: 0.26978743076324463\n",
      "Batch 321 (samples 1926), Loss: 0.2307756394147873\n",
      "Batch 331 (samples 1986), Loss: 0.2565549612045288\n",
      "Batch 341 (samples 2046), Loss: 0.17976336181163788\n",
      "Batch 351 (samples 2106), Loss: 0.2576013505458832\n",
      "Batch 361 (samples 2166), Loss: 0.27981504797935486\n",
      "Batch 371 (samples 2226), Loss: 0.29581278562545776\n",
      "Batch 381 (samples 2286), Loss: 0.2697100043296814\n",
      "Batch 391 (samples 2346), Loss: 0.235557422041893\n",
      "Batch 401 (samples 2406), Loss: 0.2821640074253082\n",
      "Batch 411 (samples 2466), Loss: 0.2348542958498001\n",
      "Batch 421 (samples 2526), Loss: 0.267433226108551\n",
      "Batch 431 (samples 2586), Loss: 0.23156042397022247\n",
      "Batch 441 (samples 2646), Loss: 0.19623495638370514\n",
      "Batch 451 (samples 2706), Loss: 0.2978927195072174\n",
      "Batch 461 (samples 2766), Loss: 0.3043048083782196\n",
      "Batch 471 (samples 2826), Loss: 0.2760430574417114\n",
      "Batch 481 (samples 2886), Loss: 0.28054603934288025\n",
      "Batch 491 (samples 2946), Loss: 0.22592376172542572\n",
      "Batch 501 (samples 3006), Loss: 0.17888063192367554\n",
      "Batch 511 (samples 3066), Loss: 0.2897900938987732\n",
      "Batch 521 (samples 3126), Loss: 0.24245013296604156\n",
      "Batch 531 (samples 3186), Loss: 0.2781358063220978\n",
      "Batch 541 (samples 3246), Loss: 0.24788203835487366\n",
      "Batch 551 (samples 3306), Loss: 0.25393882393836975\n",
      "Batch 561 (samples 3366), Loss: 0.2391985058784485\n",
      "Batch 571 (samples 3426), Loss: 0.2572370171546936\n",
      "Batch 581 (samples 3486), Loss: 0.295686274766922\n",
      "Batch 591 (samples 3546), Loss: 0.289075642824173\n",
      "Batch 601 (samples 3606), Loss: 0.32922303676605225\n",
      "Batch 611 (samples 3666), Loss: 0.1800842136144638\n",
      "Batch 621 (samples 3726), Loss: 0.3233906030654907\n",
      "Batch 631 (samples 3786), Loss: 0.24556152522563934\n",
      "Batch 641 (samples 3846), Loss: 0.2816828191280365\n",
      "Batch 651 (samples 3906), Loss: 0.24217666685581207\n",
      "Batch 661 (samples 3966), Loss: 0.24970658123493195\n",
      "Batch 671 (samples 4026), Loss: 0.20766417682170868\n",
      "Batch 681 (samples 4086), Loss: 0.2671959400177002\n",
      "Batch 691 (samples 4146), Loss: 0.21985359489917755\n",
      "Batch 701 (samples 4206), Loss: 0.22239834070205688\n",
      "Batch 711 (samples 4266), Loss: 0.2823430895805359\n",
      "Batch 721 (samples 4326), Loss: 0.2546864151954651\n",
      "Batch 731 (samples 4386), Loss: 0.23164398968219757\n",
      "Batch 741 (samples 4446), Loss: 0.2584666907787323\n",
      "Batch 751 (samples 4506), Loss: 0.20486052334308624\n",
      "Batch 761 (samples 4566), Loss: 0.23893645405769348\n",
      "Batch 771 (samples 4626), Loss: 0.24971218407154083\n",
      "Batch 781 (samples 4686), Loss: 0.2176329642534256\n",
      "Batch 791 (samples 4746), Loss: 0.30549198389053345\n",
      "Batch 801 (samples 4806), Loss: 0.20205126702785492\n",
      "Batch 811 (samples 4866), Loss: 0.28004467487335205\n",
      "Batch 821 (samples 4926), Loss: 0.24427753686904907\n",
      "Batch 831 (samples 4986), Loss: 0.32778990268707275\n",
      "Batch 841 (samples 5046), Loss: 0.25288742780685425\n",
      "Batch 851 (samples 5106), Loss: 0.2047082632780075\n",
      "Batch 861 (samples 5166), Loss: 0.25227469205856323\n",
      "Batch 871 (samples 5226), Loss: 0.21604254841804504\n",
      "Batch 881 (samples 5286), Loss: 0.23965364694595337\n",
      "Batch 891 (samples 5346), Loss: 0.2829376757144928\n",
      "Batch 901 (samples 5406), Loss: 0.3060402274131775\n",
      "Batch 911 (samples 5466), Loss: 0.19080013036727905\n",
      "Batch 921 (samples 5526), Loss: 0.2598438560962677\n",
      "Batch 931 (samples 5586), Loss: 0.2331322282552719\n",
      "Batch 941 (samples 5646), Loss: 0.2412721961736679\n",
      "Batch 951 (samples 5706), Loss: 0.20300345122814178\n",
      "Batch 961 (samples 5766), Loss: 0.28171420097351074\n",
      "Batch 971 (samples 5826), Loss: 0.2160801887512207\n",
      "Batch 981 (samples 5886), Loss: 0.3056110441684723\n",
      "Batch 991 (samples 5946), Loss: 0.28114962577819824\n",
      "Batch 1001 (samples 6006), Loss: 0.2514413297176361\n",
      "Batch 1011 (samples 6066), Loss: 0.2722805440425873\n",
      "Batch 1021 (samples 6126), Loss: 0.21986128389835358\n",
      "Batch 1031 (samples 6186), Loss: 0.26934096217155457\n",
      "Batch 1041 (samples 6246), Loss: 0.19010423123836517\n",
      "Batch 1051 (samples 6306), Loss: 0.22590702772140503\n",
      "Batch 1061 (samples 6366), Loss: 0.21973274648189545\n",
      "Batch 1071 (samples 6426), Loss: 0.25971195101737976\n",
      "Batch 1081 (samples 6486), Loss: 0.32372012734413147\n",
      "Batch 1091 (samples 6546), Loss: 0.21411295235157013\n",
      "Batch 1101 (samples 6606), Loss: 0.3000822365283966\n",
      "Batch 1111 (samples 6666), Loss: 0.31037506461143494\n",
      "Batch 1121 (samples 6726), Loss: 0.24510282278060913\n",
      "Batch 1131 (samples 6786), Loss: 0.24599309265613556\n",
      "Batch 1141 (samples 6846), Loss: 0.2488301396369934\n",
      "Batch 1151 (samples 6906), Loss: 0.1891087144613266\n",
      "Batch 1161 (samples 6966), Loss: 0.32238471508026123\n",
      "Batch 1171 (samples 7026), Loss: 0.22279652953147888\n",
      "Batch 1181 (samples 7086), Loss: 0.2994250953197479\n",
      "Batch 1191 (samples 7146), Loss: 0.24123229086399078\n",
      "Batch 1201 (samples 7206), Loss: 0.2705572247505188\n",
      "Batch 1211 (samples 7266), Loss: 0.35886338353157043\n",
      "Batch 1221 (samples 7326), Loss: 0.1878724992275238\n",
      "Batch 1231 (samples 7386), Loss: 0.19543267786502838\n",
      "Batch 1241 (samples 7446), Loss: 0.2893376648426056\n",
      "Batch 1251 (samples 7506), Loss: 0.22784003615379333\n",
      "Batch 1261 (samples 7566), Loss: 0.2768298089504242\n",
      "Batch 1271 (samples 7626), Loss: 0.28818365931510925\n",
      "Batch 1281 (samples 7686), Loss: 0.2494712620973587\n",
      "Batch 1291 (samples 7746), Loss: 0.22876501083374023\n",
      "Batch 1301 (samples 7806), Loss: 0.1944534182548523\n",
      "Batch 1311 (samples 7866), Loss: 0.2734581530094147\n",
      "Batch 1321 (samples 7926), Loss: 0.2879478633403778\n",
      "Batch 1331 (samples 7986), Loss: 0.30436497926712036\n",
      "Batch 1341 (samples 8046), Loss: 0.2582683265209198\n",
      "Batch 1351 (samples 8106), Loss: 0.2008659541606903\n",
      "Batch 1361 (samples 8166), Loss: 0.30650657415390015\n",
      "Batch 1371 (samples 8226), Loss: 0.30757012963294983\n",
      "Batch 1381 (samples 8286), Loss: 0.22848179936408997\n",
      "Batch 1391 (samples 8346), Loss: 0.2345888316631317\n",
      "Batch 1401 (samples 8406), Loss: 0.2120766043663025\n",
      "Batch 1411 (samples 8466), Loss: 0.2802670896053314\n",
      "Batch 1421 (samples 8526), Loss: 0.22714127600193024\n",
      "Batch 1431 (samples 8586), Loss: 0.3155902922153473\n",
      "Batch 1441 (samples 8646), Loss: 0.32243412733078003\n",
      "Batch 1451 (samples 8706), Loss: 0.25259929895401\n",
      "Batch 1461 (samples 8766), Loss: 0.29946935176849365\n",
      "Batch 1471 (samples 8826), Loss: 0.21588777005672455\n",
      "Batch 1481 (samples 8886), Loss: 0.22850289940834045\n",
      "Batch 1491 (samples 8946), Loss: 0.26310238242149353\n",
      "Batch 1501 (samples 9006), Loss: 0.20563450455665588\n",
      "Batch 1511 (samples 9066), Loss: 0.47152960300445557\n",
      "Batch 1521 (samples 9126), Loss: 0.24903646111488342\n",
      "Batch 1531 (samples 9186), Loss: 0.23948977887630463\n",
      "Batch 1541 (samples 9246), Loss: 0.23509256541728973\n",
      "Batch 1551 (samples 9306), Loss: 0.18814846873283386\n",
      "Batch 1561 (samples 9366), Loss: 0.2532571852207184\n",
      "Batch 1571 (samples 9426), Loss: 0.24604815244674683\n",
      "Batch 1581 (samples 9486), Loss: 0.28660130500793457\n",
      "Batch 1591 (samples 9546), Loss: 0.22688795626163483\n",
      "Batch 1601 (samples 9606), Loss: 0.24514542520046234\n",
      "Batch 1611 (samples 9666), Loss: 0.24570393562316895\n",
      "Batch 1621 (samples 9726), Loss: 0.27350759506225586\n",
      "Batch 1631 (samples 9786), Loss: 0.16904667019844055\n",
      "Batch 1641 (samples 9846), Loss: 0.29307594895362854\n",
      "Batch 1651 (samples 9906), Loss: 0.18664631247520447\n",
      "Batch 1661 (samples 9966), Loss: 0.22169575095176697\n",
      "Batch 1671 (samples 10026), Loss: 0.24007660150527954\n",
      "Batch 1681 (samples 10086), Loss: 0.2424471378326416\n",
      "Batch 1691 (samples 10146), Loss: 0.26583683490753174\n",
      "Batch 1701 (samples 10206), Loss: 0.2427753210067749\n",
      "Batch 1711 (samples 10266), Loss: 0.2445577085018158\n",
      "Batch 1721 (samples 10326), Loss: 0.2119220793247223\n",
      "Batch 1731 (samples 10386), Loss: 0.29209595918655396\n",
      "Batch 1741 (samples 10446), Loss: 0.2798822820186615\n",
      "Batch 1751 (samples 10506), Loss: 0.31567734479904175\n",
      "Batch 1761 (samples 10566), Loss: 0.25820082426071167\n",
      "Batch 1771 (samples 10626), Loss: 0.19249868392944336\n",
      "Batch 1781 (samples 10686), Loss: 0.2696587145328522\n",
      "Batch 1791 (samples 10746), Loss: 0.19422505795955658\n",
      "Batch 1801 (samples 10806), Loss: 0.23895879089832306\n",
      "Batch 1811 (samples 10866), Loss: 0.24653686583042145\n",
      "Batch 1821 (samples 10926), Loss: 0.3062758445739746\n",
      "Batch 1831 (samples 10986), Loss: 0.20062211155891418\n",
      "Batch 1841 (samples 11046), Loss: 0.2765711545944214\n",
      "Batch 1851 (samples 11106), Loss: 0.2774443030357361\n",
      "Batch 1861 (samples 11166), Loss: 0.34559890627861023\n",
      "Batch 1871 (samples 11226), Loss: 0.22146755456924438\n",
      "Batch 1881 (samples 11286), Loss: 0.2568129301071167\n",
      "Batch 1891 (samples 11346), Loss: 0.29460805654525757\n",
      "Batch 1901 (samples 11406), Loss: 0.23283548653125763\n",
      "Batch 1911 (samples 11466), Loss: 0.2505180239677429\n",
      "Batch 1921 (samples 11526), Loss: 0.18299178779125214\n",
      "Batch 1931 (samples 11586), Loss: 0.28216004371643066\n",
      "Batch 1941 (samples 11646), Loss: 0.26888933777809143\n",
      "Batch 1951 (samples 11706), Loss: 0.24374577403068542\n",
      "Batch 1961 (samples 11766), Loss: 0.2978877127170563\n",
      "Batch 1971 (samples 11826), Loss: 0.2671935558319092\n",
      "Batch 1981 (samples 11886), Loss: 0.2943851053714752\n",
      "Batch 1991 (samples 11946), Loss: 0.25004249811172485\n",
      "Batch 2001 (samples 12006), Loss: 0.28988146781921387\n",
      "Batch 2011 (samples 12066), Loss: 0.22781246900558472\n",
      "Batch 2021 (samples 12126), Loss: 0.36708977818489075\n",
      "Batch 2031 (samples 12186), Loss: 0.24922405183315277\n",
      "Batch 2041 (samples 12246), Loss: 0.2597710192203522\n",
      "Batch 2051 (samples 12306), Loss: 0.27504822611808777\n",
      "Batch 2061 (samples 12366), Loss: 0.23086243867874146\n",
      "Batch 2071 (samples 12426), Loss: 0.2226535975933075\n",
      "Batch 2081 (samples 12486), Loss: 0.20262280106544495\n",
      "Batch 2091 (samples 12546), Loss: 0.21518263220787048\n",
      "Batch 2101 (samples 12606), Loss: 0.23082135617733002\n",
      "Batch 2111 (samples 12666), Loss: 0.19667616486549377\n",
      "Batch 2121 (samples 12726), Loss: 0.26707497239112854\n",
      "Batch 2131 (samples 12786), Loss: 0.2661827802658081\n",
      "Batch 2141 (samples 12846), Loss: 0.22307728230953217\n",
      "Batch 2151 (samples 12906), Loss: 0.18888814747333527\n",
      "Batch 2161 (samples 12966), Loss: 0.19709844887256622\n",
      "Batch 2171 (samples 13026), Loss: 0.25115808844566345\n",
      "Batch 2181 (samples 13086), Loss: 0.2994832992553711\n",
      "Batch 2191 (samples 13146), Loss: 0.3031710088253021\n",
      "Batch 2201 (samples 13206), Loss: 0.2439042627811432\n",
      "Batch 2211 (samples 13266), Loss: 0.3054940104484558\n",
      "Batch 2221 (samples 13326), Loss: 0.22482629120349884\n",
      "Batch 2231 (samples 13386), Loss: 0.2073722630739212\n",
      "Batch 2241 (samples 13446), Loss: 0.279565691947937\n",
      "Batch 2251 (samples 13506), Loss: 0.2764214873313904\n",
      "Batch 2261 (samples 13566), Loss: 0.2931962311267853\n",
      "Batch 2271 (samples 13626), Loss: 0.2296440154314041\n",
      "Batch 2281 (samples 13686), Loss: 0.23944053053855896\n",
      "Batch 2291 (samples 13746), Loss: 0.24862028658390045\n",
      "Batch 2301 (samples 13806), Loss: 0.2514539659023285\n",
      "Batch 2311 (samples 13866), Loss: 0.3556179702281952\n",
      "Batch 2321 (samples 13926), Loss: 0.2581060826778412\n",
      "Batch 2331 (samples 13986), Loss: 0.1882663369178772\n",
      "Batch 2341 (samples 14046), Loss: 0.2584044933319092\n",
      "Batch 2351 (samples 14106), Loss: 0.38429078459739685\n",
      "Batch 2361 (samples 14166), Loss: 0.22743164002895355\n",
      "Batch 2371 (samples 14226), Loss: 0.2661984860897064\n",
      "Batch 2381 (samples 14286), Loss: 0.2678162455558777\n",
      "Batch 2391 (samples 14346), Loss: 0.25434285402297974\n",
      "Batch 2401 (samples 14406), Loss: 0.31016045808792114\n",
      "Batch 2411 (samples 14466), Loss: 0.19067513942718506\n",
      "Batch 2421 (samples 14526), Loss: 0.31635913252830505\n",
      "Batch 2431 (samples 14586), Loss: 0.29406335949897766\n",
      "Batch 2441 (samples 14646), Loss: 0.2996938228607178\n",
      "Batch 2451 (samples 14706), Loss: 0.29339680075645447\n",
      "Batch 2461 (samples 14766), Loss: 0.2854934334754944\n",
      "Batch 2471 (samples 14826), Loss: 0.22314508259296417\n",
      "Batch 2481 (samples 14886), Loss: 0.2558278441429138\n",
      "Batch 2491 (samples 14946), Loss: 0.25222718715667725\n",
      "Batch 2501 (samples 15006), Loss: 0.3068851828575134\n",
      "Batch 2511 (samples 15066), Loss: 0.31379514932632446\n",
      "Batch 2521 (samples 15126), Loss: 0.28551334142684937\n",
      "Batch 2531 (samples 15186), Loss: 0.22112005949020386\n",
      "Batch 2541 (samples 15246), Loss: 0.24656054377555847\n",
      "Batch 2551 (samples 15306), Loss: 0.24511364102363586\n",
      "Batch 2561 (samples 15366), Loss: 0.2968031167984009\n",
      "Batch 2571 (samples 15426), Loss: 0.22084058821201324\n",
      "Batch 2581 (samples 15486), Loss: 0.2664240002632141\n",
      "Batch 2591 (samples 15546), Loss: 0.2702995538711548\n",
      "Batch 2601 (samples 15606), Loss: 0.2762181758880615\n",
      "Batch 2611 (samples 15666), Loss: 0.19703982770442963\n",
      "Batch 2621 (samples 15726), Loss: 0.24951523542404175\n",
      "Batch 2631 (samples 15786), Loss: 0.2964024543762207\n",
      "Batch 2641 (samples 15846), Loss: 0.22745771706104279\n",
      "Batch 2651 (samples 15906), Loss: 0.2144346684217453\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_785384/3346108546.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_generated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/deep_iglu_denoiser/utils/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_train_examples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"std\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_train_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/deep_iglu_denoiser/utils/dataloader.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, filepath, target, mean, std)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTarget\u001b[0m \u001b[0mframe\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMean\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mStandard\u001b[0m \u001b[0mdeviation\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtifffile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop_pad_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_multiple_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mtarget_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/sgia/lib/python3.9/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(files, aszarr, key, series, level, squeeze, maxworkers, mode, name, offset, size, pattern, axesorder, categories, imread, sort, container, chunkshape, dtype, axestiled, ioworkers, chunkmode, fillvalue, zattrs, multiscales, omexml, out, out_inplace, _multifile, _useframes, **kwargs)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         if isinstance(files, str) or not isinstance(\n\u001b[1;32m   1060\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         ):\n\u001b[0;32m-> 1062\u001b[0;31m             with TiffFile(\n\u001b[0m\u001b[1;32m   1063\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/sgia/lib/python3.9/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, file, mode, name, offset, size, omexml, _multifile, _useframes, _parent, **is_flags)\u001b[0m\n\u001b[1;32m   4096\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0museframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4098\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4099\u001b[0m             \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4100\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mambaforge/envs/sgia/lib/python3.9/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, arg, index)\u001b[0m\n\u001b[1;32m   7099\u001b[0m         )\n\u001b[1;32m   7100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7101\u001b[0m         \u001b[0;31m# read and cache first page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7102\u001b[0m         \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7103\u001b[0;31m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTiffPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpageindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keyframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nextpageoffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/sgia/lib/python3.9/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, parent, index, keyframe)\u001b[0m\n\u001b[1;32m   7777\u001b[0m                     \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtagoffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtagsize_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtagdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7778\u001b[0m                 )\n\u001b[1;32m   7779\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTiffFileError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7780\u001b[0m                 \u001b[0mlog_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self!r} {exc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7781\u001b[0;31m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7782\u001b[0m             \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/sgia/lib/python3.9/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, parent, offset, header, validate)\u001b[0m\n\u001b[1;32m  10628\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTIFF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTAG_READERS\u001b[0m  \u001b[0;31m# TODO: only works with offsets?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10629\u001b[0m         ):\n\u001b[1;32m  10630\u001b[0m             \u001b[0mvalueoffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsetformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10631\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTIFF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTAG_LOAD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10632\u001b[0;31m                 value = TiffTag._read_value(\n\u001b[0m\u001b[1;32m  10633\u001b[0m                     \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalueoffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10634\u001b[0m                 )\n\u001b[1;32m  10635\u001b[0m             elif (\n",
      "\u001b[0;32m~/mambaforge/envs/sgia/lib/python3.9/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(parent, offset, code, dtype, count, valueoffset)\u001b[0m\n\u001b[1;32m  10707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10708\u001b[0m         \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalueoffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTIFF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTAG_READERS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10710\u001b[0m             \u001b[0mreadfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTIFF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTAG_READERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10711\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsetsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10712\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10713\u001b[0m             \u001b[0;31m# BYTES, ASCII, UNDEFINED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10714\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvaluesize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/sgia/lib/python3.9/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(fh, byteorder, dtype, count, offsetsize, planecount)\u001b[0m\n\u001b[1;32m  19126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtagid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m41\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  19127\u001b[0m                 \u001b[0;31m# silently skip unexpected tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  19128\u001b[0m                 \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  19129\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 19130\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_uic_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplanecount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  19131\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  19132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/sgia/lib/python3.9/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(fh, tagid, planecount, offset)\u001b[0m\n\u001b[1;32m  19213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  19214\u001b[0m     \u001b[0mFraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTIFF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUIC_TAGS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  19215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  19216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 19217\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  19218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  19219\u001b[0m             \u001b[0moff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  19220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moff\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/envs/sgia/lib/python3.9/site-packages/tifffile/tifffile.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  14056\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14057\u001b[0m         \u001b[0;34m\"\"\"Return file's current position.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14058\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 14059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    i = 0\n",
    "    while not dataloader.epoch_done:\n",
    "        batch_generated = dataloader.get_batch()\n",
    "        if not batch_generated:\n",
    "            break\n",
    "        data = dataloader.X.to(device)\n",
    "        targets = dataloader.y.to(device)\n",
    "        model.train()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f'Batch {i+1} (samples {(i+1)*dataloader.batch_size}), Loss: {loss.item()}')\n",
    "        i += 1\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    dataloader.shuffle_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'unet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.modelwrapper import ModelWrapper\n",
    "wrapper = ModelWrapper('unet.pt',2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1310719 into shape (1,4,512,512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/stephan/Desktop/deep_iglu_denoiser/train.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bromolus/home/stephan/Desktop/deep_iglu_denoiser/train.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m wrapper\u001b[39m.\u001b[39;49mdenoise_img(\u001b[39m'\u001b[39;49m\u001b[39m/home/stephan/Desktop/students_10.05._old/Bachelorkurs_2023/Coverslip2 evoked spontan R8 ttx.stk\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/deep_iglu_denoiser/model/modelwrapper.py:51\u001b[0m, in \u001b[0;36mModelWrapper.denoise_img\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_img(img_path)\n\u001b[1;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m target \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_pre \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_post):\n\u001b[0;32m---> 51\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_prediction_frames(target)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     52\u001b[0m     y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(X)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m     53\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_height, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_width\n\u001b[1;32m     54\u001b[0m     )\n\u001b[1;32m     55\u001b[0m     denoised_image_sequence\u001b[39m.\u001b[39mappend(y_pred)\n",
      "File \u001b[0;32m~/Desktop/deep_iglu_denoiser/model/modelwrapper.py:44\u001b[0m, in \u001b[0;36mModelWrapper.get_prediction_frames\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m     42\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdelete(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_pre)\n\u001b[1;32m     43\u001b[0m \u001b[39m# reshape to batch size 1\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_pre \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_post, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimg_height, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimg_width)\n\u001b[1;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(X, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1310719 into shape (1,4,512,512)"
     ]
    }
   ],
   "source": [
    "wrapper.denoise_img('/home/stephan/Desktop/students_10.05._old/Bachelorkurs_2023/Coverslip2 evoked spontan R8 ttx.stk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "x = np.random.random((512,512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(25600).reshape(100,16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.normalization import rolling_window_z_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = rolling_window_z_norm(x,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 16, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils.activitymap\n",
    "reload(utils.activitymap)\n",
    "from utils.activitymap import compute_activitymap\n",
    "t = compute_activitymap(x,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb4d3e1e9d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0],cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb4d3ea3460>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(t[0],cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0,1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 3],\n",
       "       [0, 2, 0],\n",
       "       [0, 2, 1],\n",
       "       [0, 2, 2],\n",
       "       [0, 2, 3],\n",
       "       [0, 3, 0],\n",
       "       [0, 3, 1],\n",
       "       [0, 3, 2],\n",
       "       [0, 3, 3],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 3],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 3],\n",
       "       [1, 2, 0],\n",
       "       [1, 2, 1],\n",
       "       [1, 2, 2],\n",
       "       [1, 2, 3],\n",
       "       [1, 3, 0],\n",
       "       [1, 3, 1],\n",
       "       [1, 3, 2],\n",
       "       [1, 3, 3],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 3],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 3],\n",
       "       [2, 2, 0],\n",
       "       [2, 2, 1],\n",
       "       [2, 2, 2],\n",
       "       [2, 2, 3],\n",
       "       [2, 3, 0],\n",
       "       [2, 3, 1],\n",
       "       [2, 3, 2],\n",
       "       [2, 3, 3],\n",
       "       [3, 0, 0],\n",
       "       [3, 0, 1],\n",
       "       [3, 0, 2],\n",
       "       [3, 0, 3],\n",
       "       [3, 1, 0],\n",
       "       [3, 1, 1],\n",
       "       [3, 1, 2],\n",
       "       [3, 1, 3],\n",
       "       [3, 2, 0],\n",
       "       [3, 2, 1],\n",
       "       [3, 2, 2],\n",
       "       [3, 2, 3],\n",
       "       [3, 3, 0],\n",
       "       [3, 3, 1],\n",
       "       [3, 3, 2],\n",
       "       [3, 3, 3],\n",
       "       [4, 0, 0],\n",
       "       [4, 0, 1],\n",
       "       [4, 0, 2],\n",
       "       [4, 0, 3],\n",
       "       [4, 1, 0],\n",
       "       [4, 1, 1],\n",
       "       [4, 1, 2],\n",
       "       [4, 1, 3],\n",
       "       [4, 2, 0],\n",
       "       [4, 2, 1],\n",
       "       [4, 2, 2],\n",
       "       [4, 2, 3],\n",
       "       [4, 3, 0],\n",
       "       [4, 3, 1],\n",
       "       [4, 3, 2],\n",
       "       [4, 3, 3],\n",
       "       [5, 0, 0],\n",
       "       [5, 0, 1],\n",
       "       [5, 0, 2],\n",
       "       [5, 0, 3],\n",
       "       [5, 1, 0],\n",
       "       [5, 1, 1],\n",
       "       [5, 1, 2],\n",
       "       [5, 1, 3],\n",
       "       [5, 2, 0],\n",
       "       [5, 2, 1],\n",
       "       [5, 2, 2],\n",
       "       [5, 2, 3],\n",
       "       [5, 3, 0],\n",
       "       [5, 3, 1],\n",
       "       [5, 3, 2],\n",
       "       [5, 3, 3],\n",
       "       [6, 0, 0],\n",
       "       [6, 0, 1],\n",
       "       [6, 0, 2],\n",
       "       [6, 0, 3],\n",
       "       [6, 1, 0],\n",
       "       [6, 1, 1],\n",
       "       [6, 1, 2],\n",
       "       [6, 1, 3],\n",
       "       [6, 2, 0],\n",
       "       [6, 2, 1],\n",
       "       [6, 2, 2],\n",
       "       [6, 2, 3],\n",
       "       [6, 3, 0],\n",
       "       [6, 3, 1],\n",
       "       [6, 3, 2],\n",
       "       [6, 3, 3],\n",
       "       [7, 0, 0],\n",
       "       [7, 0, 1],\n",
       "       [7, 0, 2],\n",
       "       [7, 0, 3],\n",
       "       [7, 1, 0],\n",
       "       [7, 1, 1],\n",
       "       [7, 1, 2],\n",
       "       [7, 1, 3],\n",
       "       [7, 2, 0],\n",
       "       [7, 2, 1],\n",
       "       [7, 2, 2],\n",
       "       [7, 2, 3],\n",
       "       [7, 3, 0],\n",
       "       [7, 3, 1],\n",
       "       [7, 3, 2],\n",
       "       [7, 3, 3],\n",
       "       [8, 0, 0],\n",
       "       [8, 0, 1],\n",
       "       [8, 0, 2],\n",
       "       [8, 0, 3],\n",
       "       [8, 1, 0],\n",
       "       [8, 1, 1],\n",
       "       [8, 1, 2],\n",
       "       [8, 1, 3],\n",
       "       [8, 2, 0],\n",
       "       [8, 2, 1],\n",
       "       [8, 2, 2],\n",
       "       [8, 2, 3],\n",
       "       [8, 3, 0],\n",
       "       [8, 3, 1],\n",
       "       [8, 3, 2],\n",
       "       [8, 3, 3],\n",
       "       [9, 0, 0],\n",
       "       [9, 0, 1],\n",
       "       [9, 0, 2],\n",
       "       [9, 0, 3],\n",
       "       [9, 1, 0],\n",
       "       [9, 1, 1],\n",
       "       [9, 1, 2],\n",
       "       [9, 1, 3],\n",
       "       [9, 2, 0],\n",
       "       [9, 2, 1],\n",
       "       [9, 2, 2],\n",
       "       [9, 2, 3],\n",
       "       [9, 3, 0],\n",
       "       [9, 3, 1],\n",
       "       [9, 3, 2],\n",
       "       [9, 3, 3]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(t > 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sgia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
